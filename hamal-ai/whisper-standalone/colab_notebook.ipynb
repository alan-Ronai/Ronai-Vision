{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ™ï¸ Hebrew Whisper Transcription Service\n",
        "\n",
        "This notebook runs a Hebrew speech-to-text service using faster-whisper.\n",
        "\n",
        "**Features:**\n",
        "- GPU-accelerated transcription\n",
        "- File upload transcription\n",
        "- Live RTP/TCP audio transcription\n",
        "- Hebrew-optimized ivrit-ai model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1ï¸âƒ£ Setup & Installation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q faster-whisper python-dotenv numpy\n",
        "\n",
        "# Check GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the service files (or upload them manually)\n",
        "# Option 1: Clone from your repo\n",
        "# !git clone https://github.com/YOUR_REPO/whisper-standalone.git\n",
        "# %cd whisper-standalone\n",
        "\n",
        "# Option 2: Upload files manually using Colab's file upload"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2ï¸âƒ£ Initialize Transcriber"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "from whisper_transcriber import WhisperTranscriber\n",
        "\n",
        "# Initialize with GPU (use 'cpu' if no GPU)\n",
        "transcriber = WhisperTranscriber(\n",
        "    model_path=\"ivrit-ai/whisper-large-v3-turbo-ct2\",\n",
        "    device=\"cuda\",  # or 'cpu'\n",
        "    compute_type=\"float16\",  # use 'int8' for CPU\n",
        ")\n",
        "\n",
        "# Load model (downloads on first run)\n",
        "transcriber.load_model()\n",
        "print(\"âœ… Transcriber ready!\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3ï¸âƒ£ Transcribe Files"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload a file using Colab's file upload\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded: {filename}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transcribe the uploaded file\n",
        "result = transcriber.transcribe_file(filename)\n",
        "\n",
        "if result:\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"TRANSCRIPTION ({result.duration_seconds:.1f}s)\")\n",
        "    print(\"=\" * 70)\n",
        "    print(result.text)\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    # Show segments\n",
        "    if result.segments:\n",
        "        print(\"\\nSegments:\")\n",
        "        for i, seg in enumerate(result.segments, 1):\n",
        "            print(f\"  [{i}] {seg['start']:.1f}s - {seg['end']:.1f}s: {seg['text']}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4ï¸âƒ£ Live RTP Transcription (Optional)\n",
        "\n",
        "Connect to your EC2 RTP relay for live radio transcription."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "RTP_HOST = \"YOUR_EC2_IP\"  # Replace with your EC2 relay IP\n",
        "RTP_PORT = 5005"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "from rtp_client import RTPTCPClient\n",
        "\n",
        "# Audio buffer\n",
        "audio_buffer = []\n",
        "buffer_lock = threading.Lock()\n",
        "SAMPLE_RATE = 16000\n",
        "BUFFER_DURATION = 4.0\n",
        "\n",
        "def on_audio(audio_data, sample_rate):\n",
        "    with buffer_lock:\n",
        "        audio_buffer.append(audio_data)\n",
        "        total = sum(len(c) // 2 for c in audio_buffer) / SAMPLE_RATE\n",
        "        if total >= BUFFER_DURATION:\n",
        "            process_buffer()\n",
        "\n",
        "def process_buffer():\n",
        "    global audio_buffer\n",
        "    with buffer_lock:\n",
        "        if not audio_buffer:\n",
        "            return\n",
        "        audio_bytes = b\"\".join(audio_buffer)\n",
        "        audio_buffer = []\n",
        "    \n",
        "    result = transcriber.transcribe_audio(audio_bytes)\n",
        "    if result and result.text:\n",
        "        print(f\"ğŸ™ï¸ {result.text}\")\n",
        "\n",
        "# Start RTP client\n",
        "rtp_client = RTPTCPClient(\n",
        "    host=RTP_HOST,\n",
        "    port=RTP_PORT,\n",
        "    audio_callback=on_audio,\n",
        ")\n",
        "rtp_client.start()\n",
        "print(f\"ğŸ“¡ Connected to {RTP_HOST}:{RTP_PORT}\")\n",
        "print(\"Listening for live audio...\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run for a while, then stop\n",
        "import time\n",
        "\n",
        "try:\n",
        "    print(\"Running... Press Stop (â¹ï¸) to stop\")\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "rtp_client.stop()\n",
        "print(\"Stopped.\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5ï¸âƒ£ Batch Transcription"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Transcribe multiple files\n",
        "import glob\n",
        "\n",
        "# Upload multiple files first, then:\n",
        "audio_files = glob.glob(\"*.wav\") + glob.glob(\"*.mp3\")\n",
        "print(f\"Found {len(audio_files)} audio files\")\n",
        "\n",
        "for filepath in audio_files:\n",
        "    print(f\"\\nğŸ“ Processing: {filepath}\")\n",
        "    result = transcriber.transcribe_file(filepath)\n",
        "    if result:\n",
        "        print(f\"ğŸ“ {result.text[:200]}...\" if len(result.text) > 200 else f\"ğŸ“ {result.text}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
